# -*- coding: utf-8 -*-
"""Akın_Bektaş_152120211066.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ti9Tfcuedg7r3nv2BL8ivgRbwwaqXY6L
"""

import os
import cv2
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import matplotlib.pyplot as plt
import torchvision.transforms as transforms
from torch.utils.data import DataLoader, Dataset

# Cihaz ayarı (GPU varsa kullan)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Veri seti yolu
DATASET_PATH = "/content/drive/MyDrive/wood_dataset/wood"
IMG_SIZE = (256, 256)
PADDING = 10  # Kenarları yumuşatmak için dolgu

# Veri seti sınıfı
class WoodDataset(Dataset):
    def __init__(self, image_paths):
        self.image_paths = image_paths
        self.transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.5], std=[0.5])
        ])

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        image = cv2.imread(self.image_paths[idx], cv2.IMREAD_GRAYSCALE)
        image = cv2.copyMakeBorder(image, PADDING, PADDING, PADDING, PADDING, cv2.BORDER_REFLECT)
        image = cv2.resize(image, IMG_SIZE)
        image = self.transform(image)
        return image

# Eğitim ve test veri yolları
train_images = [os.path.join(DATASET_PATH, "train/good", img) for img in os.listdir(os.path.join(DATASET_PATH, "train/good"))]
test_images = [
    os.path.join(DATASET_PATH, "test/good", img) for img in os.listdir(os.path.join(DATASET_PATH, "test/good"))
] + [
    os.path.join(DATASET_PATH, "test/defect", img) for img in os.listdir(os.path.join(DATASET_PATH, "test/defect"))
]

# Veri yükleyiciler
train_dataset = WoodDataset(train_images)
train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)

test_dataset = WoodDataset(test_images)
test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)

# Autoencoder Modeli
class Autoencoder(nn.Module):
    def __init__(self):
        super(Autoencoder, self).__init__()
        self.encoder = nn.Sequential(
            nn.Conv2d(1, 16, 3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2, 2),
            nn.Conv2d(16, 32, 3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2, 2),
            nn.Conv2d(32, 64, 3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2, 2)
        )
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(64, 32, 2, stride=2),
            nn.ReLU(),
            nn.ConvTranspose2d(32, 16, 2, stride=2),
            nn.ReLU(),
            nn.ConvTranspose2d(16, 1, 2, stride=2),
            nn.Sigmoid()
        )

    def forward(self, x):
        x = self.encoder(x)
        x = self.decoder(x)
        return x

# U-Net Modeli
class UNet(nn.Module):
    def __init__(self):
        super(UNet, self).__init__()
        self.encoder = nn.Sequential(
            nn.Conv2d(1, 64, 3, padding=1), nn.ReLU(),
            nn.MaxPool2d(2, 2),
            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(),
            nn.MaxPool2d(2, 2)
        )
        self.middle = nn.Sequential(
            nn.Conv2d(128, 256, 3, padding=1), nn.ReLU(),
            nn.Conv2d(256, 128, 3, padding=1), nn.ReLU()
        )
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(128, 64, 2, stride=2), nn.ReLU(),
            nn.ConvTranspose2d(64, 1, 2, stride=2), nn.Sigmoid()
        )

    def forward(self, x):
        x = self.encoder(x)
        x = self.middle(x)
        x = self.decoder(x)
        return x

# Model Tanımlamaları
models = {"Autoencoder": Autoencoder().to(device), "U-Net": UNet().to(device)}
criterion = nn.MSELoss()
optimizers = {name: optim.Adam(model.parameters(), lr=0.001) for name, model in models.items()}

# Test ve Kenar Hatasını Düzeltme
for model_name, model in models.items():
    print(f"{model_name} Test Ediliyor")
    model.eval()
    with torch.no_grad():
        for images in test_loader:
            images = images.to(device)
            outputs = model(images)
            error_map = F.mse_loss(outputs, images, reduction='none').mean(dim=1)

            # Kenar hatalarını sıfırlama
            roi = (slice(20, 236), slice(20, 236))
            masked_error_map = torch.zeros_like(error_map)
            masked_error_map[:, roi[0], roi[1]] = error_map[:, roi[0], roi[1]]

            anomaly_mask = (masked_error_map > 0.01).float()

            plt.figure(figsize=(12, 4))
            plt.subplot(1, 3, 1)
            plt.imshow(images[0].cpu().detach().squeeze(), cmap='gray')
            plt.title("Giriş Görüntüsü")

            plt.subplot(1, 3, 2)
            plt.imshow(masked_error_map[0].cpu().detach().numpy(), cmap='jet')
            plt.title(f"Düzeltilmiş Hata Haritası ({model_name})")

            plt.subplot(1, 3, 3)
            plt.imshow(anomaly_mask[0].cpu().detach().numpy(), cmap='gray')
            plt.title(f"Segmentasyon Maskesi ({model_name})")

            plt.show()

